## 数据准备

Faiss 处理固定维度的向量集合，维度范围通常在几十到几百之间。这些集合可以存储在矩阵中。我们假设使用行优先存储，即第 i 个向量的第 j 个分量存储在矩阵的第i行第j列中。Faiss 仅支持 32位浮点矩阵。

需要准备两个矩阵：
- `xb`: 数据库向量组成的矩阵，包含所有需要被索引和搜索的向量，尺寸为 `nb-by-d (nb×d)`
  - `nb, number of batches/samples` 代表向量的数量，`d, dimensions/features` 代表每个向量的维度，`xb` 是一个 `nb` 行 `d` 列的矩阵，每一行代表一个向量
- `xq`: 查询向量组成的矩阵，需要查找最近邻的查询向量集合，尺寸为 `nq-by-d (nq×d)`
  - `nq, nb of queries` 是查询向量的数量，`d` 是每个查询向量的维度
  - 当我们需要为一个查询向量找到最近的邻居时，`nq` 就等于 1

以下示例使用64维的均匀分布（uniform distribution）向量，并在第一个维度添加与向量索引相关的小偏移量以增加数据区分度。

### Python实现

```python
import numpy as np
d = 64                           # 向量维度
nb = 100000                      # 数据库规模
nq = 10000                       # 查询数量
np.random.seed(1234)             # 设置随机种子保证可复现
xb = np.random.random((nb, d)).astype('float32')
xb[:, 0] += np.arange(nb) / 1000.  # 添加索引相关偏移
xq = np.random.random((nq, d)).astype('float32')
xq[:, 0] += np.arange(nq) / 1000.
```

在 Python 中矩阵使用 numpy 数组表示，必须确保数据类型为 `float32`。

## 索引构建与数据添加

Faiss的核心是 `Index` 对象，它封装数据库向量集并支持高效搜索。我们将使用最简单的 `IndexFlatL2` 索引进行暴力L2距离搜索。

所有索引初始化时需指定向量维度 `d`。多数索引需要训练阶段分析数据分布，但 `IndexFlatL2` 可跳过此步骤。

索引构建后支持两个核心操作：
1. `add`: 向索引中添加向量
  - `is_trained`, 表示是否需要训练
  - `ntotal`, 已索引向量数量
2. `search`: 执行近邻搜索

### Python实现

```python
import faiss
index = faiss.IndexFlatL2(d)   # 创建L2距离索引
print(index.is_trained)        # 输出True（该索引无需训练）
index.add(xb)                  # 添加数据库向量
print(index.ntotal)            # 显示已索引向量总数
```

### 运行结果
应显示True（索引已就绪）和100000（数据库向量总数）。

## 近邻搜索

基础搜索操作是k-近邻搜索，即对每个查询向量找出数据库中k个最近邻。搜索结果存储为nq×k的整型矩阵（邻居ID）和浮点矩阵（平方距离）。

### Python实现

```python
k = 4                          # 查询4个最近邻
D, I = index.search(xb[:5], k) # 完整性检查
print(I)
print(D)
D, I = index.search(xq, k)     # 实际搜索
print(I[:5])                   # 前5个查询结果
print(I[-5:])                  # 后5个查询结果
```

### 预期结果
完整性检查应显示：
```
[[  0 393 363  78]
 [  1 555 277 364]
 [  2 304 101  13]
 [  3 173  18 182]
 [  4 288 370 531]]

[[ 0.          7.17517328  7.2076292   7.25116253]
 [ 0.          6.32356453  6.6845808   6.79994535]
 [ 0.          5.79640865  6.39173603  7.28151226]
 [ 0.          7.27790546  7.52798653  7.66284657]
 [ 0.          6.76380348  7.29512024  7.36881447]]
```
实际搜索结果示例：
```
[[ 381  207  210  477]
 [ 526  911  142   72]
 [ 838  527 1290  425]
 [ 196  184  164  359]
 [ 526  377  120  425]]

[[ 9900 10500  9309  9831]
 [11055 10895 10812 11321]
 [11353 11103 10164  9787]
 [10571 10664 10632  9638]
 [ 9628  9554 10036  9582]]
```

因数据在首维添加偏移量，前几个查询结果集中在数据集起始位置，约10000号查询结果则集中在10000号索引附近。

当向量的第一个分量（即第一个维度）增加值时，整个数据集沿着第一个轴被“涂抹”或“拉伸”。这意味着数据集中的向量在第一个维度上变得更加分散。具体来说，数据集中前几个向量的邻居（即相似度较高的向量）会集中在数据集的开始部分，而接近10000索引的向量的邻居则会集中在数据集的索引10000附近。这种现象可能是因为增加第一个分量的值导致向量在第一个维度上的距离增加，使得数据集在该维度上的分布变得更加稀疏，从而影响了向量之间的邻近性。这种变化可能会对基于邻近性的机器学习算法（如k-近邻算法）产生影响，因为它们依赖于向量之间的距离来确定相似度。
